{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> **Label**\t**Description**\n",
    "<br> 0 T-shirt/top\n",
    "<br> 1 Trouser\n",
    "<br> 2 Pullover\n",
    "<br> 3 Dress\n",
    "<br> 4 Coat\n",
    "<br> 5 Sandal\n",
    "<br> 6 Shirt\n",
    "<br> 7 Sneaker\n",
    "<br> 8 Bag\n",
    "<br> 9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x188aab23e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1454ae33b969>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m          validation_data=(x_valid, y_valid))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jinesh\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1144\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinesh\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         exception_prefix='input')\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinesh\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    181\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    184\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
